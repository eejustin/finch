{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finch: Personal Injury Case Scoring Demo\n",
    "\n",
    "This notebook demonstrates the key features of the Finch pipeline: extracting structured features from call transcripts, training and evaluating a logistic regression model, and scoring new leads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jsonlines\n",
    "from lead_score import extract_key_elements_with_llm, score_lead, score_lead_with_model\n",
    "from llm_logreg_features import process_llm_outputs, train_logistic_regression\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Example Transcripts\n",
    "\n",
    "We'll load a small sample of transcripts for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Adjust this path to your sample transcripts file\n",
    "transcript_path = 'filtered_transcripts.jsonl'\n",
    "sample_transcripts = []\n",
    "with jsonlines.open(transcript_path) as reader:\n",
    "    for i, obj in enumerate(reader):\n",
    "        if i >= 3: break  # Only show a few for demo\n",
    "        sample_transcripts.append(obj)\n",
    "pd.DataFrame(sample_transcripts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract Structured Features with LLM\n",
    "\n",
    "We'll use the OpenAI LLM to extract structured fields from each transcript. (This requires a valid OpenAI API key in your config.)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "llm_outputs = []\n",
    "for record in sample_transcripts:\n",
    "    llm_result_str = extract_key_elements_with_llm(record)\n",
    "    # Remove markdown formatting if present\n",
    "    import re, json\n",
    "    cleaned = re.sub(r'^```json|```$', '', llm_result_str.strip(), flags=re.MULTILINE).strip()\n",
    "    try:\n",
    "        llm_result = json.loads(cleaned)\n",
    "    except Exception:\n    import ast\n    try:\n        llm_result = ast.literal_eval(cleaned)\n    except Exception:\n        llm_result = {'raw_output': llm_result_str}\n",
    "    merged = dict(record)\n",
    "    merged.update(llm_result)\n",
    "    llm_outputs.append(merged)\n",
    "pd.DataFrame(llm_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Convert LLM Outputs to ML Features\n",
    "\n",
    "We convert the extracted fields into numeric features for model training."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Write LLM outputs to a temporary JSONL for feature conversion\n",
    "import tempfile\n",
    "tmp_jsonl = tempfile.NamedTemporaryFile(mode='w+', delete=False, suffix='.jsonl')\n",
    "for obj in llm_outputs:\n",
    "    tmp_jsonl.write(json.dumps(obj) + '\\n')\n",
    "tmp_jsonl.close()\n",
    "tmp_csv = tempfile.NamedTemporaryFile(mode='w+', delete=False, suffix='.csv')\n",
    "process_llm_outputs(tmp_jsonl.name, tmp_csv.name, label_field='label')\n",
    "tmp_csv.close()\n",
    "features_df = pd.read_csv(tmp_csv.name)\n",
    "features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train Logistic Regression Model\n",
    "\n",
    "Let's train a logistic regression model on these features (demo only; use more data for real training)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = train_logistic_regression(features_df, label_col='label')\n",
    "# Save model for later demo\n",
    "joblib.dump(model, 'demo_logreg_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Score New Leads\n",
    "\n",
    "We can now score new leads using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "scored = []\n",
    "for record in llm_outputs:\n",
    "    result = score_lead_with_model(record, 'demo_logreg_model.joblib')\n",
    "    record.update(result)\n",
    "    scored.append(record)\n",
    "pd.DataFrame(scored)[['call_id', 'model_score', 'label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Results\n",
    "\n",
    "Let's plot the model scores for a quick look."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "scores = [r['model_score'] for r in scored]\n",
    "plt.hist(scores, bins=10)\n",
    "plt.xlabel('Predicted Probability of Positive Outcome')\n",
    "plt.ylabel('Number of Leads')\n",
    "plt.title('Distribution of Model Scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This notebook demonstrates the core workflow of the Finch pipeline: LLM extraction, feature engineering, ML model training, and model-based scoring. For production, use larger datasets and proper train/test splits."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
